# CAP6415_F25_project-Finding-and-solving-hard-to-detect-classes-using-synthetic-images
CAP6415_F25_project-Finding and solving hard-to-detect classes using synthetic images


Abstract

# ğŸš€ Training a Vision Model Using Unity-Generated Synthetic Data

**Improving Under-Represented Classes with Synthetic Book Images**

---

## ğŸ“„ Overview

This project investigates whether **Unity-generated synthetic images** can reliably improve performance for **under-represented classes** when training YOLOv8.

A real-world dataset was available, but the **â€œbookâ€** class had very few examples.
To address this, **100 synthetic book images** were generated inside Unity, converted to YOLO format, and **merged into the real training dataset**.

Two models are compared:

| Model               | Description                                                       |
| ------------------- | ----------------------------------------------------------------- |
| **Pure SOTA Model** | Official YOLOv8n pretrained on COCO (no custom training)          |
| **Trained Model**   | Fine-tuned using the real dataset **+ 100 synthetic book images** |

A custom evaluation pipeline measures improvement in:

* precision
* recall
* F1
* overall accuracy
* per-class behaviour and error trends

An **interactive HTML performance dashboard** summarizes all results.
Source: 

---

# ğŸ§  Key Components

| Component                           | Purpose                                              |
| ----------------------------------- | ---------------------------------------------------- |
| **Unity Perception**                | Synthetic image generation & 2D bbox labeling        |
| **Perception2YOLO**                 | Conversion of Unity metadata â†’ YOLO format           |
| **YOLOv8 (Ultralytics)**            | Training and inference                               |
| **SOTA_test.py / TRAINING_test.py** | Real-dataset evaluation                              |
| **model_comparison.html**           | Interactive analysis dashboard comparing both models |

---

# ğŸ“ Repository Structure

```
1. unity_project/
   â”œâ”€ Assets/
   â””â”€ GeneratedDataset/
        â””â”€ YOLO/                      # created by Perception2YOLO

2. SOTA Training/
   â”œâ”€ datasets/
   â”‚   â”œâ”€ real_dataset/               # real evaluation images
   â”‚   â”œâ”€ TrainingDataset(NonMixed).zip
   â”‚   â”‚     # contains REAL images for all classes
   â”‚   â”‚     # user must paste their YOLO-converted synthetic images here
   â”‚   â””â”€ train_dataset/              # final merged dataset used for training
   â”œâ”€ Training.ipynb
   â”œâ”€ yolov8n.pt
   â””â”€ runs/                           # YOLO training outputs

3. Test & Results/
   â””â”€ Testing/
       â”œâ”€ real_dataset/
       â”œâ”€ SOTA_test.py                # Pure SOTA Model evaluation
       â”œâ”€ TRAINING_test.py            # Trained Model evaluation
       â””â”€ TrainedModel.pt             # produced by Training.ipynb

model_comparison.html                 # Interactive analysis dashboard
```

---

# ğŸ² Unity Synthetic Dataset Generation

### Scene Used

```
Assets/Scenes/SyntheticDataScene.unity
```

### Randomizers (Final Version)

* **PrefabPlacementRandomizer**
* **RotationRandomizer**

No lighting or camera randomizers are used â€” controlled environment for reproducibility.

### Export location

```
unity_project/GeneratedDataset/
```

Run **Perception2YOLO** to convert into YOLO format:

```
GeneratedDataset/YOLO/
   images/train/
   images/val/
   labels/train/
   labels/val/
   dataset.yaml
```

---

# ğŸ“¦ Training Dataset (Real + 100 Synthetic Images)

You are provided:

```
TrainingDataset(NonMixed).zip
```

This zip contains **real images for all 5 classes**, including â€œbookâ€, but the synthetic set must be added manually.

### **How to use it**

1. Unzip:

   ```
   2. SOTA Training/datasets/TrainingDataset(NonMixed)/
   ```
2. Generate synthetic book images â†’ use Perception2YOLO.
3. Paste generated:

   ```
   images/train/   (real + 100 synthetic book)
   labels/train/
   ```

   into the TrainingDataset folder.
4. Rename it as the final training dataset:

   ```
   train_dataset/
   ```

This merged dataset is used for YOLO training.

---

# ğŸ‹ï¸ Training (YOLOv8)

Run:

```
2. SOTA Training/Training.ipynb
```

Set:

```python
DATASET_ROOT = "2. SOTA Training/datasets/train_dataset"
DATA_YAML = f"{DATASET_ROOT}/dataset.yaml"
MODEL = "yolov8n.pt"
```

Outputs:

```
runs/detect/training_run/
   â”œâ”€ weights/best.pt
   â”œâ”€ results.csv
   â”œâ”€ results.png
```

Rename:

```
best.pt â†’ 3. Test & Results/Testing/TrainedModel.pt
```

---

# ğŸ“Š Evaluation Pipeline

Located in:

```
3. Test & Results/Testing/
```

### Pure SOTA Model

```bash
python SOTA_test.py
```

### Trained Model (real + synthetic)

```bash
python TRAINING_test.py
```

### Outputs

```
<OUT_DIR>/
   results.csv
   per_class_metrics.csv
   confusion_matrix.html
   summary.json
```

---

# ğŸ“ˆ Final Results (Visual + Interactive)

An interactive dashboard summarizing both models is included:

**`model_comparison.html`**
Contains:

* side-by-side per-class precision, recall, F1
* radar charts
* grouped comparison bars
* F1 deltas
* confusion matrix trends
* raw numeric results
* CSV export

ğŸ“ **Cited source:** 

---

# ğŸ§ª Findings (Short Summary)

### **1. Synthetic data dramatically fixes the â€œbookâ€ class.**

Recall increased from **8.8% â†’ 79.4%**, F1 from **0.16 â†’ 0.87**.

### **2. Overall accuracy improves substantially.**

* Pure SOTA Model: **0.681**
* Trained Model: **0.960**

### **3. Cross-class generalization improves.**

Even classes not augmented through synthetic data (cup, chair, laptop) show measurable recall improvements.

### **4. Synthetic variance bridges the domain gap.**

Unity-generated images provided the missing texture/pose diversity needed for the model to properly learn â€œbookâ€.

---

# ğŸ Conclusion

* Synthetic Unity data is a **practical and effective** method to improve weak classes in real-world datasets.
* Even **100 synthetic images** produced large, measurable gains.
* The Trained Model consistently outperforms the Pure SOTA baseline across all metrics.
* The included dashboard provides an in-depth, visual understanding of the improvements.

---

# ğŸ”— Files Included

* `model_comparison.html` â€“ Full interactive analytics 
* `TrainingDataset(NonMixed).zip` â€“ real-image training base
* `Perception2YOLO` â€“ converter script
* `SOTA_test.py` / `TRAINING_test.py` â€“ evaluation scripts
* `Training.ipynb` â€“ training workflow


